{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas.io.data\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Pima = pd.read_csv('labs/data/pima-indians-diabetes.csv', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1   2   3    4     5      6   7  8\n",
       "0  6  148  72  35    0  33.6  0.627  50  1\n",
       "1  1   85  66  29    0  26.6  0.351  31  0\n",
       "2  8  183  64   0    0  23.3  0.672  32  1\n",
       "3  1   89  66  23   94  28.1  0.167  21  0\n",
       "4  0  137  40  35  168  43.1  2.288  33  1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pima.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pima.columns=['timespregnant', 'glucoseconc', 'dbp', 'trithickness', 'twohourins', 'bmi', 'pedigreef', 'age', 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timespregnant</th>\n",
       "      <th>glucoseconc</th>\n",
       "      <th>dbp</th>\n",
       "      <th>trithickness</th>\n",
       "      <th>twohourins</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigreef</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timespregnant  glucoseconc  dbp  trithickness  twohourins   bmi  pedigreef  \\\n",
       "0              6          148   72            35           0  33.6      0.627   \n",
       "1              1           85   66            29           0  26.6      0.351   \n",
       "2              8          183   64             0           0  23.3      0.672   \n",
       "3              1           89   66            23          94  28.1      0.167   \n",
       "4              0          137   40            35         168  43.1      2.288   \n",
       "\n",
       "   age  class  \n",
       "0   50      1  \n",
       "1   31      0  \n",
       "2   32      1  \n",
       "3   21      0  \n",
       "4   33      1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pima.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>timespregnant</th>\n",
       "      <td>768</td>\n",
       "      <td>3.845052</td>\n",
       "      <td>3.369578</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glucoseconc</th>\n",
       "      <td>768</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>0.000</td>\n",
       "      <td>99.00000</td>\n",
       "      <td>117.0000</td>\n",
       "      <td>140.25000</td>\n",
       "      <td>199.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dbp</th>\n",
       "      <td>768</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>0.000</td>\n",
       "      <td>62.00000</td>\n",
       "      <td>72.0000</td>\n",
       "      <td>80.00000</td>\n",
       "      <td>122.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trithickness</th>\n",
       "      <td>768</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twohourins</th>\n",
       "      <td>768</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>127.25000</td>\n",
       "      <td>846.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>768</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.000</td>\n",
       "      <td>27.30000</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>36.60000</td>\n",
       "      <td>67.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedigreef</th>\n",
       "      <td>768</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.24375</td>\n",
       "      <td>0.3725</td>\n",
       "      <td>0.62625</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>768</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>21.000</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>81.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>768</td>\n",
       "      <td>0.348958</td>\n",
       "      <td>0.476951</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count        mean         std     min       25%       50%  \\\n",
       "timespregnant    768    3.845052    3.369578   0.000   1.00000    3.0000   \n",
       "glucoseconc      768  120.894531   31.972618   0.000  99.00000  117.0000   \n",
       "dbp              768   69.105469   19.355807   0.000  62.00000   72.0000   \n",
       "trithickness     768   20.536458   15.952218   0.000   0.00000   23.0000   \n",
       "twohourins       768   79.799479  115.244002   0.000   0.00000   30.5000   \n",
       "bmi              768   31.992578    7.884160   0.000  27.30000   32.0000   \n",
       "pedigreef        768    0.471876    0.331329   0.078   0.24375    0.3725   \n",
       "age              768   33.240885   11.760232  21.000  24.00000   29.0000   \n",
       "class            768    0.348958    0.476951   0.000   0.00000    0.0000   \n",
       "\n",
       "                     75%     max  \n",
       "timespregnant    6.00000   17.00  \n",
       "glucoseconc    140.25000  199.00  \n",
       "dbp             80.00000  122.00  \n",
       "trithickness    32.00000   99.00  \n",
       "twohourins     127.25000  846.00  \n",
       "bmi             36.60000   67.10  \n",
       "pedigreef        0.62625    2.42  \n",
       "age             41.00000   81.00  \n",
       "class            1.00000    1.00  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pima.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEACAYAAABS29YJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c6cc860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = Pima['trithickness'][~Pima.trithickness.isnull()].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEACAYAAABS29YJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAExJJREFUeJzt3W+spGdZx/Hfz25LBIRDE7P9G09ftEANusW0okiYYKnF\nSFvfYJtgdpHwpgqkLwhd3izRpClEBIIBEm3ZhaSrDZhmawS7xT7JGpIWtAOl27XdtEe7xT0VpUhN\nNiz28sU823s4npmzPeeeue+d+/tJJjvPM3/u61xnznXm/OaZWUeEAACL7WdKFwAAmD2GPQA0gGEP\nAA1g2ANAAxj2ANAAhj0ANGDqsLd9se0HbD9q+7u2P9DvP9f2QduP277P9tLYbXbbfsL2EdvXzPoL\nAABszNOOs7d9nqTzImJo+5WS/knSDZLeI+n7EfFx2x+W9JqIuNX25ZLuknSlpAsl3S/psoh4YdZf\nCABgsqnP7CPieEQM+/PPS3pMoyF+naR9/dX2afQLQJKul7Q/Ik5GxIqko5KumkHdAICX4LQze9vL\nkq6Q9KCk7RGx2l+0Kml7f/4CScfGbnZMo18OAICCTmvY9xHOVyR9MCJ+NH5ZjHKgaZ+5wOcxAEBh\n2za6gu2zNRr0X4qIe/rdq7bPi4jjts+X9Gy//xlJF4/d/KJ+39r75BcAAGxCRHgzt9voaBxLukPS\n4Yj41NhFByTt7M/vlHTP2P4bbZ9j+xJJl0p6aELBnCK0Z8+e4jXUcqIX9IJeTD9txUbP7N8s6d2S\nvmP74X7fbkm3S7rb9nslrUh6Vz/AD9u+W9JhST+RdHNstcIFt7KyUrqEatCLhF4k9CKPqcM+Iv5R\nk5/9Xz3hNrdJum2LdQEAMuIdtIXt2rWrdAnVoBcJvUjoRR5T31Q1s0Vt0h0AeIlsK2bxAi1mr+u6\n0iVUg14k9CKhF3kw7AGgAcQ4AHCGIMYBAEzFsC+MPDKhFwm9SOhFHgx7AGgAmT0AnCHI7AEAUzHs\nCyOPTOhFQi8SepEHwx4AGkBmDwBnCDJ7AMBUDPvCyCMTepHQi4Re5MGwB4AGkNkDwBliK5n9hv/h\nOM4Mo/8uuBx+eQN1I8YpLG8eGYVOeZDNJvQioRd5MOwBoAFk9gtiFOOU6qmJcYA54Dh7AMBUDPvC\nyCMTepHQi4Re5MGwB4AGkNkvCDJ7YPGR2QMApmLYF0YemdCLhF4k9CIPhj0ANIDMfkGQ2QOLj8we\nADAVw74w8siEXiT0IqEXeTDsAaABZPYLgsweWHxk9gCAqRj2hZFHJvQioRcJvciDYQ8ADSCzXxBk\n9sDiI7MHAEzFsC+MPDKhFwm9SOhFHgx7AGgAmf2CILMHFh+ZPQBgKoZ9YeSRCb1I6EVCL/Jg2ANA\nA8jsFwSZPbD4yOwBAFMx7Asjj0zoRUIvEnqRx4bD3vadtldtPzK276O2j9l+uD+9Y+yy3bafsH3E\n9jWzKhwAcPo2zOxtv0XS85K+GBFv6PftkfSjiPizNde9XNJdkq6UdKGk+yVdFhEvrLkemX1mZPbA\n4ptpZh8RhyT9YL1119l3vaT9EXEyIlYkHZV01WYKAwDks5XM/v22v237DttL/b4LJB0bu84xjZ7h\nYwLyyIReJPQioRd5bNvk7T4n6Y/7838i6ROS3jvhuuv+fb9r1y4tLy9LkpaWlrRjxw4NBgNJ6ZvL\n9kvbTk5tD+a0PaohV/219LPk9nA4rKqektvD4bCqeua53XWd9u7dK0kvzsvNOq3j7G0vS7r3VGY/\n6TLbt0pSRNzeX/Y1SXsi4sE1tyGzz4zMHlh8cz/O3vb5Y5u/K+nUkToHJN1o+xzbl0i6VNJDm1kD\nAJDP6Rx6uV/SNyS91vbTtv9A0sdsf8f2tyW9VdItkhQRhyXdLemwpK9Kupmn8NP9/wimXfQioRcJ\nvchjw8w+Im5aZ/edU65/m6TbtlIUACAvPhtnQZDZA4uPz8YBAEzFsC+MPDKhFwm9SOhFHgx7AGgA\nmf2CILMHFt9WMvvNvoMW6xgNXACoDzFOdvESTw9s4jbrnc58ZLMJvUjoRR4MewBoAJl9RqVzczJ7\nYLFxnD0AYCqGfXFd6QKqQTab0IuEXuTBsAeABpDZZ0RmD2CWyOwBAFMx7IvrShdQDbLZhF4k9CIP\nhj0ANIDMPiMyewCzRGYPAJiKYV9cV7qAapDNJvQioRd5MOwBoAFk9hmR2QOYJTJ7AMBUDPviutIF\nVINsNqEXCb3Ig2EPAA0gs8+IzB7ALJHZAwCmYtgX15UuoBpkswm9SOhFHgx7AGgAmX1GZPYAZonM\nHgAwFcO+uK50AdUgm03oRUIv8thWugAshlGENX/ER8DpIbPPqOXMvszavFaAtpDZAwCmYtgX15Uu\noCJd6QKqQU6d0Is8GPYA0AAy+4zI7Oe/7iI+joBJyOwBAFMx7IvrShdQka50AdUgp07oRR4MewBo\nAJl9RmT28193ER9HwCRk9gCAqRj2xXWlC6hIV7qAapBTJ/QiD4Y9ADSAzD4jMvv5r7uIjyNgEjJ7\nAMBUDPviutIFVKQrXUA1yKkTepHHhsPe9p22V20/MrbvXNsHbT9u+z7bS2OX7bb9hO0jtq+ZVeEA\ngNO3YWZv+y2Snpf0xYh4Q7/v45K+HxEft/1hSa+JiFttXy7pLklXSrpQ0v2SLouIF9bcJ5l9/tUb\nXJvMHm2ZaWYfEYck/WDN7usk7evP75N0Q3/+ekn7I+JkRKxIOirpqs0UBgDIZ7OZ/faIWO3Pr0ra\n3p+/QNKxsesd0+gZPibqShdQka50AdUgp07oRR5b/j9oIyJsT/tbet3Ldu3apeXlZUnS0tKSduzY\nocFgICl9c8+07eTU9mDO26XWP7Vvq/enDS5f//q1fP9zbg+Hw6rqKbk9HA6rqmee213Xae/evZL0\n4rzcrNM6zt72sqR7xzL7I5IGEXHc9vmSHoiI19m+VZIi4vb+el+TtCciHlxzf2T2+VdvcG0ye7Sl\nxHH2ByTt7M/vlHTP2P4bbZ9j+xJJl0p6aJNrAAAyOZ1DL/dL+oak19p+2vZ7JN0u6e22H5f0tn5b\nEXFY0t2SDkv6qqSbF/IpfFZd6QIq0pUuoBrk1Am9yGPDzD4ibppw0dUTrn+bpNu2UhQAIC8+Gycj\nMvv5r7uIjyNgEj4bBwAwFcO+uK50ARXpShdQDXLqhF7kwbAHgAaQ2WdEZj//dRfxcQRMQmYPAJiK\nYV9cV7qAinSlC6gGOXVCL/Jg2ANAA8jsMyKzn/+6i/g4AiYhswcATMWwL64rXUBFutIFVIOcOqEX\neTDsAaABZPYZkdnPf91FfBwBk5DZAwCmYtgX15UuoCJd6QKqQU6d0Is8GPYA0AAy+4zI7Oe/7iI+\njoBJyOwBAFMx7IvrShdQka50AdUgp07oRR4MewBoAJl9RmT28193ER9HwCRk9gCAqRj2xXWlC6hI\nV7qAapBTJ/QiD4Y9ADSAzD4jMvv5r7uIjyNgEjJ7AMBUDPviutIFVKQrXUA1yKkTepEHwx4AGkBm\nnxGZ/fzXXcTHETAJmT0AYCqGfXFd6QIq0pUuoBrk1Am9yINhDwANILPPiMx+/usu4uMImITMHgAw\nFcO+uK50ARXpShdQDXLqhF7kwbAHgAaQ2WdEZj//dRfxcQRMQmYPAJiKYV9cV7qAinSlC6gGOXVC\nL/Jg2ANAAxYqs3/yySf1mc98TqVi3E9/+k/VXm5ecm0ye7RlK5n9ttzFlPTMM8/o85//sk6cuLnA\n6ocKrAkAp2ehhr0kvexlF+nEiQ8VWPlsSfdu4nadpEHWSs5cnejFSNd1GgwGpcuoAr3Ig8weABrA\nsC9uULqAigxKF1ANnskm9CIPhj0ANIBhX1xXuoCKdKULqAbHlif0Io8tvUBre0XSf0v6X0knI+Iq\n2+dK+mtJvyBpRdK7IuK5LdYJANiCrT6zD0mDiLgiIq7q990q6WBEXCbp6/02JhqULqAig9IFVIOc\nOqEXeeSIcdYe4H+dpH39+X2SbsiwBgBgC3I8s7/f9rdsv6/ftz0iVvvzq5K2b3GNBdeVLqAiXekC\nqkFOndCLPLb6pqo3R8S/2/55SQdtHxm/MCLC9rrvZ9+1a5eWl5clSUtLS9qxY8eLf66d+ua+1O2z\nzjqrv/eu/3cwx+2jSkqsP27e65/at9X70waXr3/9zT5eat4eDodV1VNyezgcVlXPPLe7rtPevXsl\n6cV5uVnZPhvH9h5Jz0t6n0Y5/nHb50t6ICJet+a6M/lsnEOHDumd7/yIfvjDEh9d8ClJt6i9z6cp\nuTafjYO2FPk8e9svt/1z/flXSLpG0iOSDkja2V9tp6R7NrsGACCPrWT22yUdsj2U9KCkv42I+yTd\nLuntth+X9LZ+GxN1pQuoSFe6gGqQUyf0Io9NZ/YR8ZSkHevs/y9JV2+lKABAXryDtrhB6QIqMihd\nQDU4tjyhF3kw7AGgAQz74rrSBVSkK11ANcipE3qRB8MeABrAsC9uULqAigxKF1ANcuqEXuTBsAeA\nBjDsi+tKF1CRrnQB1SCnTuhFHgx7AGgAw764QekCKjIoXUA1yKkTepEHwx4AGsCwL64rXUBFutIF\nVIOcOqEXeWz18+yBouxNfdprFny8Ms4kDPviBqULqMhgE7cp+Rn+s0NOndCLPIhxAKABDPviutIF\nVKQrXUA1yKkTepEHwx4AGsCwL25QuoCKDEoXUA1y6oRe5MGwB4AGMOyL60oXUJGudAHVIKdO6EUe\nDHsAaADDvrhB6QIqMihdQDXIqRN6kQfDHgAawLAvritdQEW60gVUg5w6oRd5MOwBoAEM++IGpQuo\nyKB0AdUgp07oRR4MewBoAMO+uK50ARXpShdQDXLqhF7kwbAHgAYw7IsblC6gIoPSBVSDnDqhF3kw\n7AGgAQz74rrSBVSkK11ANcipE3qRB8MeABrAsC9uULqAigxKF1ANcuqEXuTBsAeABjDsi+tKF1CR\nrnQB1SCnTuhFHgx7AGgAw764QekCKjIoXUA1yKkTepEHwx4AGsCwL64rXUBFutIFVIOcOqEXeTDs\nAaABDPviBqULqMigdAHVIKdO6EUeDHsAaADDvriudAEV6UoXUA1y6oRe5MGwB4AGMOyLG5QuoCKD\n0gVUg5w6oRd5MOwBoAEzGfa2r7V9xPYTtj88izUWR1e6gIp0pQt4SWwXO7WEzD6P7MPe9lmS/lzS\ntZIul3ST7dfnXmdxDEsXUJEzrRcxw9Mnp1zWluHwTHtc1GkWz+yvknQ0IlYi4qSkv5J0/QzWWRDP\nlS6gIvQioRenPPccvchhFsP+QklPj20f6/cBAArZNoP7LPp35okTj+pVr3rn3Nf98Y+f1IkTm7nl\nSuZKzmQrpQuoyMrUS0vm9hHz/RFfWVmZ63prlX6NJFe/nfsbZ/tNkj4aEdf227slvRARHxu7TnvB\nIwBkEBGb+u0zi2G/TdK/SPpNSd+T9JCkmyLisawLAQBOW/YYJyJ+YvuPJP29pLMk3cGgB4Cysj+z\nBwDUZ67voG35zVa2L7b9gO1HbX/X9gf6/efaPmj7cdv32V4qXeu82D7L9sO27+23m+yF7SXbX7b9\nmO3Dtn+14V7c0v98PGL7Ltsva6UXtu+0vWr7kbF9E79227v7WXrE9jUb3f/chj1vttJJSbdExC9K\nepOkP+y//lslHYyIyyR9vd9uxQclHVY6gqvVXnxa0t9FxOsl/ZKkI2qwF7YvlPR+Sb8SEW/QKAa+\nUe304gsazcdx637tti+X9HsazdJrJX3W9tR5Ps9n9k2/2SoijkfEsD//vKTHNHr/wXWS9vVX2yfp\nhjIVzpftiyT9tqS/lHTq6ILmemH71ZLeEhF3SqPXvCLih2qwF71tkl7eH+jxco0O8miiFxFxSNIP\n1uye9LVfL2l/RJyMiBVJRzWasRPNc9jzZque7WVJV0h6UNL2iFjtL1qVtL1QWfP2SUkfkvTC2L4W\ne3GJpP+w/QXb/2z7L2y/Qg32IiKekfQJSf+m0ZB/LiIOqsFejJn0tV+g0Qw9ZcN5Os9hzyvBkmy/\nUtJXJH0wIn40flmMXi1f+D7Z/h1Jz0bEw0rP6n9KK73Q6JnsGyV9NiLeKOl/tCamaKUXtl+j0TPZ\nZY2G2Sttv3v8Oq30Yj2n8bVP7cs8h/0zki4e275YP/2baeHZPlujQf+liLin371q+7z+8vMlPVuq\nvjn6dUnX2X5K0n5Jb7P9JbXZi2OSjkXEN/vtL2s0/I832IurJT0VEf8ZET+R9DeSfk1t9uKUST8T\na+fpRf2+ieY57L8l6VLby7bP0ejFhQNzXL8oj95zfYekwxHxqbGLDkja2Z/fKemetbddNBHxkYi4\nOCIu0egFuH+IiN9Xm704Lulp25f1u66W9Kike9VYLyT9q6Q32f7Z/uflao1ewG+xF6dM+pk4IOlG\n2+fYvkTSpRq9gXWyiJjbSdI7NHp37VFJu+e5dumTpN/QKJ8eSnq4P10r6VxJ90t6XNJ9kpZK1zrn\nvrxV0oH+fJO9kPTLkr4p6dsaPZt9dcO9+KhGBy88otELkme30guN/sr9nqQfa/T65numfe2SPtLP\n0iOSfmuj++dNVQDQAP5bQgBoAMMeABrAsAeABjDsAaABDHsAaADDHgAawLAHgAYw7AGgAf8H3HDJ\nW+PPHMgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c92fc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = Pima['trithickness'][Pima.trithickness > 0].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>timespregnant</th>\n",
       "      <td>541</td>\n",
       "      <td>3.512015</td>\n",
       "      <td>3.324759</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>5.00</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glucoseconc</th>\n",
       "      <td>541</td>\n",
       "      <td>119.822551</td>\n",
       "      <td>32.894640</td>\n",
       "      <td>0.000</td>\n",
       "      <td>97.000</td>\n",
       "      <td>115.000</td>\n",
       "      <td>140.00</td>\n",
       "      <td>199.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dbp</th>\n",
       "      <td>541</td>\n",
       "      <td>71.197782</td>\n",
       "      <td>13.007678</td>\n",
       "      <td>0.000</td>\n",
       "      <td>64.000</td>\n",
       "      <td>72.000</td>\n",
       "      <td>80.00</td>\n",
       "      <td>110.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trithickness</th>\n",
       "      <td>541</td>\n",
       "      <td>29.153420</td>\n",
       "      <td>10.476982</td>\n",
       "      <td>7.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>36.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twohourins</th>\n",
       "      <td>541</td>\n",
       "      <td>113.282810</td>\n",
       "      <td>122.735833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>90.000</td>\n",
       "      <td>165.00</td>\n",
       "      <td>846.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>541</td>\n",
       "      <td>32.774122</td>\n",
       "      <td>7.144264</td>\n",
       "      <td>0.000</td>\n",
       "      <td>27.800</td>\n",
       "      <td>32.800</td>\n",
       "      <td>36.90</td>\n",
       "      <td>67.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedigreef</th>\n",
       "      <td>541</td>\n",
       "      <td>0.504850</td>\n",
       "      <td>0.346639</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.66</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>541</td>\n",
       "      <td>31.558226</td>\n",
       "      <td>10.743768</td>\n",
       "      <td>21.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>38.00</td>\n",
       "      <td>81.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>541</td>\n",
       "      <td>0.332717</td>\n",
       "      <td>0.471622</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count        mean         std     min     25%      50%     75%  \\\n",
       "timespregnant    541    3.512015    3.324759   0.000   1.000    2.000    5.00   \n",
       "glucoseconc      541  119.822551   32.894640   0.000  97.000  115.000  140.00   \n",
       "dbp              541   71.197782   13.007678   0.000  64.000   72.000   80.00   \n",
       "trithickness     541   29.153420   10.476982   7.000  22.000   29.000   36.00   \n",
       "twohourins       541  113.282810  122.735833   0.000   0.000   90.000  165.00   \n",
       "bmi              541   32.774122    7.144264   0.000  27.800   32.800   36.90   \n",
       "pedigreef        541    0.504850    0.346639   0.085   0.259    0.417    0.66   \n",
       "age              541   31.558226   10.743768  21.000  23.000   28.000   38.00   \n",
       "class            541    0.332717    0.471622   0.000   0.000    0.000    1.00   \n",
       "\n",
       "                  max  \n",
       "timespregnant   17.00  \n",
       "glucoseconc    199.00  \n",
       "dbp            110.00  \n",
       "trithickness    99.00  \n",
       "twohourins     846.00  \n",
       "bmi             67.10  \n",
       "pedigreef        2.42  \n",
       "age             81.00  \n",
       "class            1.00  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pima[Pima.trithickness > 0].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>timespregnant</th>\n",
       "      <td>227</td>\n",
       "      <td>4.638767</td>\n",
       "      <td>3.350062</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>13.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glucoseconc</th>\n",
       "      <td>227</td>\n",
       "      <td>123.449339</td>\n",
       "      <td>29.572931</td>\n",
       "      <td>44.000</td>\n",
       "      <td>105.000</td>\n",
       "      <td>120.000</td>\n",
       "      <td>140.5000</td>\n",
       "      <td>197.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dbp</th>\n",
       "      <td>227</td>\n",
       "      <td>64.118943</td>\n",
       "      <td>28.839945</td>\n",
       "      <td>0.000</td>\n",
       "      <td>62.000</td>\n",
       "      <td>72.000</td>\n",
       "      <td>80.0000</td>\n",
       "      <td>122.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trithickness</th>\n",
       "      <td>227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twohourins</th>\n",
       "      <td>227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>227</td>\n",
       "      <td>30.129956</td>\n",
       "      <td>9.168249</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25.150</td>\n",
       "      <td>30.400</td>\n",
       "      <td>35.0500</td>\n",
       "      <td>52.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedigreef</th>\n",
       "      <td>227</td>\n",
       "      <td>0.393291</td>\n",
       "      <td>0.276871</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.5365</td>\n",
       "      <td>1.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>227</td>\n",
       "      <td>37.251101</td>\n",
       "      <td>13.062933</td>\n",
       "      <td>21.000</td>\n",
       "      <td>27.000</td>\n",
       "      <td>34.000</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>72.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>227</td>\n",
       "      <td>0.387665</td>\n",
       "      <td>0.488294</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count        mean        std     min      25%      50%  \\\n",
       "timespregnant    227    4.638767   3.350062   0.000    2.000    4.000   \n",
       "glucoseconc      227  123.449339  29.572931  44.000  105.000  120.000   \n",
       "dbp              227   64.118943  28.839945   0.000   62.000   72.000   \n",
       "trithickness     227    0.000000   0.000000   0.000    0.000    0.000   \n",
       "twohourins       227    0.000000   0.000000   0.000    0.000    0.000   \n",
       "bmi              227   30.129956   9.168249   0.000   25.150   30.400   \n",
       "pedigreef        227    0.393291   0.276871   0.078    0.203    0.282   \n",
       "age              227   37.251101  13.062933  21.000   27.000   34.000   \n",
       "class            227    0.387665   0.488294   0.000    0.000    0.000   \n",
       "\n",
       "                    75%      max  \n",
       "timespregnant    7.0000   13.000  \n",
       "glucoseconc    140.5000  197.000  \n",
       "dbp             80.0000  122.000  \n",
       "trithickness     0.0000    0.000  \n",
       "twohourins       0.0000    0.000  \n",
       "bmi             35.0500   52.900  \n",
       "pedigreef        0.5365    1.781  \n",
       "age             45.0000   72.000  \n",
       "class            1.0000    1.000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pima[Pima.trithickness == 0].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removing the missing data for tricept thickness would reduce the dataset by close to30% and would cause bias in the data as this feature is distributed differently amongst the subset with missing values and those without "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timespregnant</th>\n",
       "      <th>glucoseconc</th>\n",
       "      <th>dbp</th>\n",
       "      <th>trithickness</th>\n",
       "      <th>twohourins</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigreef</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.126762</td>\n",
       "      <td>0.136208</td>\n",
       "      <td>0.023726</td>\n",
       "      <td>0.146096</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>0.023956</td>\n",
       "      <td>0.066236</td>\n",
       "      <td>0.279319</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.167356</td>\n",
       "      <td>-0.180375</td>\n",
       "      <td>-0.025455</td>\n",
       "      <td>0.085490</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>-0.080366</td>\n",
       "      <td>-0.051612</td>\n",
       "      <td>-0.037348</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.244409</td>\n",
       "      <td>0.312088</td>\n",
       "      <td>-0.041848</td>\n",
       "      <td>-0.207439</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>-0.129547</td>\n",
       "      <td>0.085450</td>\n",
       "      <td>-0.020681</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.167356</td>\n",
       "      <td>-0.160274</td>\n",
       "      <td>-0.025455</td>\n",
       "      <td>0.024884</td>\n",
       "      <td>0.016785</td>\n",
       "      <td>-0.058012</td>\n",
       "      <td>-0.130178</td>\n",
       "      <td>-0.204015</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.226180</td>\n",
       "      <td>0.080932</td>\n",
       "      <td>-0.238569</td>\n",
       "      <td>0.146096</td>\n",
       "      <td>0.104256</td>\n",
       "      <td>0.165535</td>\n",
       "      <td>0.775458</td>\n",
       "      <td>-0.004015</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.067938</td>\n",
       "      <td>-0.024596</td>\n",
       "      <td>0.040119</td>\n",
       "      <td>-0.207439</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>-0.095269</td>\n",
       "      <td>-0.115660</td>\n",
       "      <td>-0.054015</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.049709</td>\n",
       "      <td>-0.215550</td>\n",
       "      <td>-0.156602</td>\n",
       "      <td>0.115793</td>\n",
       "      <td>0.009693</td>\n",
       "      <td>-0.014793</td>\n",
       "      <td>-0.095592</td>\n",
       "      <td>-0.120681</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.362056</td>\n",
       "      <td>-0.029621</td>\n",
       "      <td>-0.566438</td>\n",
       "      <td>-0.207439</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>0.049291</td>\n",
       "      <td>-0.144268</td>\n",
       "      <td>-0.070681</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.108532</td>\n",
       "      <td>0.382440</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.247106</td>\n",
       "      <td>0.547518</td>\n",
       "      <td>-0.022244</td>\n",
       "      <td>-0.134021</td>\n",
       "      <td>0.329319</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.244409</td>\n",
       "      <td>0.020630</td>\n",
       "      <td>0.220447</td>\n",
       "      <td>-0.207439</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>-0.476790</td>\n",
       "      <td>-0.102424</td>\n",
       "      <td>0.345985</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.009115</td>\n",
       "      <td>-0.054746</td>\n",
       "      <td>0.187660</td>\n",
       "      <td>-0.207439</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>0.083568</td>\n",
       "      <td>-0.119930</td>\n",
       "      <td>-0.054015</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.362056</td>\n",
       "      <td>0.236711</td>\n",
       "      <td>0.040119</td>\n",
       "      <td>-0.207439</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>0.089529</td>\n",
       "      <td>0.027807</td>\n",
       "      <td>0.012652</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.362056</td>\n",
       "      <td>0.090982</td>\n",
       "      <td>0.089299</td>\n",
       "      <td>-0.207439</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>-0.072915</td>\n",
       "      <td>0.413802</td>\n",
       "      <td>0.395985</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.167356</td>\n",
       "      <td>0.342239</td>\n",
       "      <td>-0.074635</td>\n",
       "      <td>0.024884</td>\n",
       "      <td>0.905674</td>\n",
       "      <td>-0.028205</td>\n",
       "      <td>-0.031544</td>\n",
       "      <td>0.429319</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.067938</td>\n",
       "      <td>0.226661</td>\n",
       "      <td>0.023726</td>\n",
       "      <td>-0.015520</td>\n",
       "      <td>0.112530</td>\n",
       "      <td>-0.092289</td>\n",
       "      <td>0.049156</td>\n",
       "      <td>0.295985</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.185585</td>\n",
       "      <td>-0.104998</td>\n",
       "      <td>-0.566438</td>\n",
       "      <td>-0.207439</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>-0.029696</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>-0.020681</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.226180</td>\n",
       "      <td>-0.014545</td>\n",
       "      <td>0.122086</td>\n",
       "      <td>0.267309</td>\n",
       "      <td>0.177542</td>\n",
       "      <td>0.205774</td>\n",
       "      <td>0.033785</td>\n",
       "      <td>-0.037348</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.185585</td>\n",
       "      <td>-0.069822</td>\n",
       "      <td>0.040119</td>\n",
       "      <td>-0.207439</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>-0.035657</td>\n",
       "      <td>-0.093030</td>\n",
       "      <td>-0.037348</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.167356</td>\n",
       "      <td>-0.089922</td>\n",
       "      <td>-0.320537</td>\n",
       "      <td>0.176399</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>0.168516</td>\n",
       "      <td>-0.123346</td>\n",
       "      <td>-0.004015</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.167356</td>\n",
       "      <td>-0.029621</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.095591</td>\n",
       "      <td>0.019150</td>\n",
       "      <td>0.038859</td>\n",
       "      <td>0.024391</td>\n",
       "      <td>-0.020681</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.049709</td>\n",
       "      <td>0.025656</td>\n",
       "      <td>0.154873</td>\n",
       "      <td>0.206702</td>\n",
       "      <td>0.183452</td>\n",
       "      <td>0.108903</td>\n",
       "      <td>0.099113</td>\n",
       "      <td>-0.104015</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.244409</td>\n",
       "      <td>-0.110023</td>\n",
       "      <td>0.122086</td>\n",
       "      <td>-0.207439</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>0.050781</td>\n",
       "      <td>-0.035814</td>\n",
       "      <td>0.279319</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.185585</td>\n",
       "      <td>0.377414</td>\n",
       "      <td>0.171267</td>\n",
       "      <td>-0.207439</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>0.116355</td>\n",
       "      <td>-0.008914</td>\n",
       "      <td>0.129319</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.303232</td>\n",
       "      <td>-0.009520</td>\n",
       "      <td>0.089299</td>\n",
       "      <td>0.146096</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>-0.044599</td>\n",
       "      <td>-0.089187</td>\n",
       "      <td>-0.070681</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.420879</td>\n",
       "      <td>0.111083</td>\n",
       "      <td>0.204054</td>\n",
       "      <td>0.125894</td>\n",
       "      <td>0.078251</td>\n",
       "      <td>0.068665</td>\n",
       "      <td>-0.093030</td>\n",
       "      <td>0.295985</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.362056</td>\n",
       "      <td>0.020630</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.055187</td>\n",
       "      <td>0.041608</td>\n",
       "      <td>-0.013302</td>\n",
       "      <td>-0.113952</td>\n",
       "      <td>0.129319</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.185585</td>\n",
       "      <td>0.131183</td>\n",
       "      <td>0.056513</td>\n",
       "      <td>-0.207439</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>0.110394</td>\n",
       "      <td>-0.091749</td>\n",
       "      <td>0.162652</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.167356</td>\n",
       "      <td>-0.120073</td>\n",
       "      <td>-0.025455</td>\n",
       "      <td>-0.055924</td>\n",
       "      <td>0.071159</td>\n",
       "      <td>-0.131037</td>\n",
       "      <td>0.006458</td>\n",
       "      <td>-0.187348</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.538526</td>\n",
       "      <td>0.121133</td>\n",
       "      <td>0.105693</td>\n",
       "      <td>-0.015520</td>\n",
       "      <td>0.035698</td>\n",
       "      <td>-0.145940</td>\n",
       "      <td>-0.096873</td>\n",
       "      <td>0.395985</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.067938</td>\n",
       "      <td>-0.019571</td>\n",
       "      <td>0.187660</td>\n",
       "      <td>-0.207439</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>0.031407</td>\n",
       "      <td>-0.057590</td>\n",
       "      <td>0.079319</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>-0.108532</td>\n",
       "      <td>-0.110023</td>\n",
       "      <td>-0.074635</td>\n",
       "      <td>-0.035722</td>\n",
       "      <td>0.094800</td>\n",
       "      <td>0.068665</td>\n",
       "      <td>-0.008060</td>\n",
       "      <td>-0.204015</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>-0.167356</td>\n",
       "      <td>-0.094947</td>\n",
       "      <td>0.040119</td>\n",
       "      <td>-0.207439</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>0.111884</td>\n",
       "      <td>-0.076378</td>\n",
       "      <td>0.145985</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>0.420879</td>\n",
       "      <td>-0.004495</td>\n",
       "      <td>0.089299</td>\n",
       "      <td>0.166298</td>\n",
       "      <td>0.082979</td>\n",
       "      <td>0.153613</td>\n",
       "      <td>0.133699</td>\n",
       "      <td>0.245985</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>-0.049709</td>\n",
       "      <td>-0.094947</td>\n",
       "      <td>-0.205783</td>\n",
       "      <td>-0.005419</td>\n",
       "      <td>0.016785</td>\n",
       "      <td>-0.017773</td>\n",
       "      <td>-0.030690</td>\n",
       "      <td>-0.120681</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>-0.167356</td>\n",
       "      <td>-0.059772</td>\n",
       "      <td>-0.091028</td>\n",
       "      <td>-0.025621</td>\n",
       "      <td>0.042790</td>\n",
       "      <td>-0.052050</td>\n",
       "      <td>-0.107975</td>\n",
       "      <td>-0.187348</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>0.303232</td>\n",
       "      <td>0.096007</td>\n",
       "      <td>0.204054</td>\n",
       "      <td>-0.207439</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>0.010543</td>\n",
       "      <td>0.111923</td>\n",
       "      <td>0.195985</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>0.538526</td>\n",
       "      <td>0.161334</td>\n",
       "      <td>0.154873</td>\n",
       "      <td>0.166298</td>\n",
       "      <td>0.071159</td>\n",
       "      <td>0.128278</td>\n",
       "      <td>0.299797</td>\n",
       "      <td>0.095985</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>0.479703</td>\n",
       "      <td>-0.104998</td>\n",
       "      <td>0.122086</td>\n",
       "      <td>0.125894</td>\n",
       "      <td>0.029788</td>\n",
       "      <td>-0.029696</td>\n",
       "      <td>0.006885</td>\n",
       "      <td>0.212652</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>-0.167356</td>\n",
       "      <td>0.131183</td>\n",
       "      <td>0.204054</td>\n",
       "      <td>0.206702</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>0.257935</td>\n",
       "      <td>-0.048624</td>\n",
       "      <td>-0.104015</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>-0.167356</td>\n",
       "      <td>-0.200475</td>\n",
       "      <td>0.040119</td>\n",
       "      <td>0.206702</td>\n",
       "      <td>-0.026950</td>\n",
       "      <td>0.213225</td>\n",
       "      <td>0.266492</td>\n",
       "      <td>-0.020681</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>-0.049709</td>\n",
       "      <td>0.332188</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.014783</td>\n",
       "      <td>0.142081</td>\n",
       "      <td>0.065684</td>\n",
       "      <td>-0.027274</td>\n",
       "      <td>0.045985</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>0.126762</td>\n",
       "      <td>0.206560</td>\n",
       "      <td>-0.058242</td>\n",
       "      <td>-0.207439</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>-0.114643</td>\n",
       "      <td>-0.125481</td>\n",
       "      <td>0.279319</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>0.009115</td>\n",
       "      <td>0.075907</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>-0.207439</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>-0.011812</td>\n",
       "      <td>0.303213</td>\n",
       "      <td>-0.187348</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>-0.167356</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.186500</td>\n",
       "      <td>-0.006855</td>\n",
       "      <td>0.104433</td>\n",
       "      <td>-0.090041</td>\n",
       "      <td>-0.087348</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>-0.049709</td>\n",
       "      <td>-0.064797</td>\n",
       "      <td>-0.058242</td>\n",
       "      <td>0.034985</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>-0.089308</td>\n",
       "      <td>-0.106267</td>\n",
       "      <td>-0.137348</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>-0.226180</td>\n",
       "      <td>0.302038</td>\n",
       "      <td>0.154873</td>\n",
       "      <td>0.237005</td>\n",
       "      <td>0.508511</td>\n",
       "      <td>0.168516</td>\n",
       "      <td>-0.106694</td>\n",
       "      <td>-0.120681</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>0.244409</td>\n",
       "      <td>0.166359</td>\n",
       "      <td>0.072906</td>\n",
       "      <td>0.115793</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>0.006072</td>\n",
       "      <td>-0.012330</td>\n",
       "      <td>0.195985</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>-0.167356</td>\n",
       "      <td>0.035706</td>\n",
       "      <td>0.154873</td>\n",
       "      <td>0.186500</td>\n",
       "      <td>0.035698</td>\n",
       "      <td>0.067175</td>\n",
       "      <td>0.249839</td>\n",
       "      <td>0.062652</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>0.185585</td>\n",
       "      <td>0.080932</td>\n",
       "      <td>0.171267</td>\n",
       "      <td>0.206702</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>-0.034533</td>\n",
       "      <td>0.095985</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>-0.226180</td>\n",
       "      <td>0.010580</td>\n",
       "      <td>0.023726</td>\n",
       "      <td>-0.207439</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>0.064194</td>\n",
       "      <td>-0.091322</td>\n",
       "      <td>0.312652</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>-0.167356</td>\n",
       "      <td>-0.074847</td>\n",
       "      <td>0.056513</td>\n",
       "      <td>-0.207439</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>0.082078</td>\n",
       "      <td>-0.117368</td>\n",
       "      <td>-0.120681</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>0.126762</td>\n",
       "      <td>0.347264</td>\n",
       "      <td>0.187660</td>\n",
       "      <td>-0.207439</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>0.052272</td>\n",
       "      <td>-0.082782</td>\n",
       "      <td>0.545985</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>-0.108532</td>\n",
       "      <td>-0.165299</td>\n",
       "      <td>-0.091028</td>\n",
       "      <td>0.055187</td>\n",
       "      <td>-0.075413</td>\n",
       "      <td>-0.053541</td>\n",
       "      <td>0.125587</td>\n",
       "      <td>-0.187348</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>0.303232</td>\n",
       "      <td>0.246761</td>\n",
       "      <td>0.040119</td>\n",
       "      <td>0.105692</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>0.178948</td>\n",
       "      <td>-0.029409</td>\n",
       "      <td>0.162652</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>0.303232</td>\n",
       "      <td>-0.160274</td>\n",
       "      <td>-0.058242</td>\n",
       "      <td>-0.207439</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>-0.141469</td>\n",
       "      <td>-0.140852</td>\n",
       "      <td>-0.004015</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.362056</td>\n",
       "      <td>-0.099973</td>\n",
       "      <td>0.056513</td>\n",
       "      <td>0.277410</td>\n",
       "      <td>0.118440</td>\n",
       "      <td>0.013523</td>\n",
       "      <td>-0.128470</td>\n",
       "      <td>0.495985</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>-0.108532</td>\n",
       "      <td>0.005555</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.065288</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>0.071646</td>\n",
       "      <td>-0.056309</td>\n",
       "      <td>-0.104015</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.067938</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.023726</td>\n",
       "      <td>0.024884</td>\n",
       "      <td>0.038062</td>\n",
       "      <td>-0.086328</td>\n",
       "      <td>-0.096873</td>\n",
       "      <td>-0.054015</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>-0.167356</td>\n",
       "      <td>0.025656</td>\n",
       "      <td>-0.074635</td>\n",
       "      <td>-0.207439</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>-0.028205</td>\n",
       "      <td>-0.052466</td>\n",
       "      <td>0.229319</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>-0.167356</td>\n",
       "      <td>-0.140174</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.105692</td>\n",
       "      <td>-0.094326</td>\n",
       "      <td>-0.023734</td>\n",
       "      <td>-0.066984</td>\n",
       "      <td>-0.170681</td>\n",
       "      <td>-0.348958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     timespregnant  glucoseconc       dbp  trithickness  twohourins       bmi  \\\n",
       "0         0.126762     0.136208  0.023726      0.146096   -0.094326  0.023956   \n",
       "1        -0.167356    -0.180375 -0.025455      0.085490   -0.094326 -0.080366   \n",
       "2         0.244409     0.312088 -0.041848     -0.207439   -0.094326 -0.129547   \n",
       "3        -0.167356    -0.160274 -0.025455      0.024884    0.016785 -0.058012   \n",
       "4        -0.226180     0.080932 -0.238569      0.146096    0.104256  0.165535   \n",
       "5         0.067938    -0.024596  0.040119     -0.207439   -0.094326 -0.095269   \n",
       "6        -0.049709    -0.215550 -0.156602      0.115793    0.009693 -0.014793   \n",
       "7         0.362056    -0.029621 -0.566438     -0.207439   -0.094326  0.049291   \n",
       "8        -0.108532     0.382440  0.007332      0.247106    0.547518 -0.022244   \n",
       "9         0.244409     0.020630  0.220447     -0.207439   -0.094326 -0.476790   \n",
       "10        0.009115    -0.054746  0.187660     -0.207439   -0.094326  0.083568   \n",
       "11        0.362056     0.236711  0.040119     -0.207439   -0.094326  0.089529   \n",
       "12        0.362056     0.090982  0.089299     -0.207439   -0.094326 -0.072915   \n",
       "13       -0.167356     0.342239 -0.074635      0.024884    0.905674 -0.028205   \n",
       "14        0.067938     0.226661  0.023726     -0.015520    0.112530 -0.092289   \n",
       "15        0.185585    -0.104998 -0.566438     -0.207439   -0.094326 -0.029696   \n",
       "16       -0.226180    -0.014545  0.122086      0.267309    0.177542  0.205774   \n",
       "17        0.185585    -0.069822  0.040119     -0.207439   -0.094326 -0.035657   \n",
       "18       -0.167356    -0.089922 -0.320537      0.176399    0.003783  0.168516   \n",
       "19       -0.167356    -0.029621  0.007332      0.095591    0.019150  0.038859   \n",
       "20       -0.049709     0.025656  0.154873      0.206702    0.183452  0.108903   \n",
       "21        0.244409    -0.110023  0.122086     -0.207439   -0.094326  0.050781   \n",
       "22        0.185585     0.377414  0.171267     -0.207439   -0.094326  0.116355   \n",
       "23        0.303232    -0.009520  0.089299      0.146096   -0.094326 -0.044599   \n",
       "24        0.420879     0.111083  0.204054      0.125894    0.078251  0.068665   \n",
       "25        0.362056     0.020630  0.007332      0.055187    0.041608 -0.013302   \n",
       "26        0.185585     0.131183  0.056513     -0.207439   -0.094326  0.110394   \n",
       "27       -0.167356    -0.120073 -0.025455     -0.055924    0.071159 -0.131037   \n",
       "28        0.538526     0.121133  0.105693     -0.015520    0.035698 -0.145940   \n",
       "29        0.067938    -0.019571  0.187660     -0.207439   -0.094326  0.031407   \n",
       "..             ...          ...       ...           ...         ...       ...   \n",
       "738      -0.108532    -0.110023 -0.074635     -0.035722    0.094800  0.068665   \n",
       "739      -0.167356    -0.094947  0.040119     -0.207439   -0.094326  0.111884   \n",
       "740       0.420879    -0.004495  0.089299      0.166298    0.082979  0.153613   \n",
       "741      -0.049709    -0.094947 -0.205783     -0.005419    0.016785 -0.017773   \n",
       "742      -0.167356    -0.059772 -0.091028     -0.025621    0.042790 -0.052050   \n",
       "743       0.303232     0.096007  0.204054     -0.207439   -0.094326  0.010543   \n",
       "744       0.538526     0.161334  0.154873      0.166298    0.071159  0.128278   \n",
       "745       0.479703    -0.104998  0.122086      0.125894    0.029788 -0.029696   \n",
       "746      -0.167356     0.131183  0.204054      0.206702   -0.094326  0.257935   \n",
       "747      -0.167356    -0.200475  0.040119      0.206702   -0.026950  0.213225   \n",
       "748      -0.049709     0.332188  0.007332      0.014783    0.142081  0.065684   \n",
       "749       0.126762     0.206560 -0.058242     -0.207439   -0.094326 -0.114643   \n",
       "750       0.009115     0.075907  0.007332     -0.207439   -0.094326 -0.011812   \n",
       "751      -0.167356     0.000530  0.072906      0.186500   -0.006855  0.104433   \n",
       "752      -0.049709    -0.064797 -0.058242      0.034985   -0.094326 -0.089308   \n",
       "753      -0.226180     0.302038  0.154873      0.237005    0.508511  0.168516   \n",
       "754       0.244409     0.166359  0.072906      0.115793   -0.094326  0.006072   \n",
       "755      -0.167356     0.035706  0.154873      0.186500    0.035698  0.067175   \n",
       "756       0.185585     0.080932  0.171267      0.206702   -0.094326  0.000111   \n",
       "757      -0.226180     0.010580  0.023726     -0.207439   -0.094326  0.064194   \n",
       "758      -0.167356    -0.074847  0.056513     -0.207439   -0.094326  0.082078   \n",
       "759       0.126762     0.347264  0.187660     -0.207439   -0.094326  0.052272   \n",
       "760      -0.108532    -0.165299 -0.091028      0.055187   -0.075413 -0.053541   \n",
       "761       0.303232     0.246761  0.040119      0.105692   -0.094326  0.178948   \n",
       "762       0.303232    -0.160274 -0.058242     -0.207439   -0.094326 -0.141469   \n",
       "763       0.362056    -0.099973  0.056513      0.277410    0.118440  0.013523   \n",
       "764      -0.108532     0.005555  0.007332      0.065288   -0.094326  0.071646   \n",
       "765       0.067938     0.000530  0.023726      0.024884    0.038062 -0.086328   \n",
       "766      -0.167356     0.025656 -0.074635     -0.207439   -0.094326 -0.028205   \n",
       "767      -0.167356    -0.140174  0.007332      0.105692   -0.094326 -0.023734   \n",
       "\n",
       "     pedigreef       age     class  \n",
       "0     0.066236  0.279319  0.651042  \n",
       "1    -0.051612 -0.037348 -0.348958  \n",
       "2     0.085450 -0.020681  0.651042  \n",
       "3    -0.130178 -0.204015 -0.348958  \n",
       "4     0.775458 -0.004015  0.651042  \n",
       "5    -0.115660 -0.054015 -0.348958  \n",
       "6    -0.095592 -0.120681  0.651042  \n",
       "7    -0.144268 -0.070681 -0.348958  \n",
       "8    -0.134021  0.329319  0.651042  \n",
       "9    -0.102424  0.345985  0.651042  \n",
       "10   -0.119930 -0.054015 -0.348958  \n",
       "11    0.027807  0.012652  0.651042  \n",
       "12    0.413802  0.395985 -0.348958  \n",
       "13   -0.031544  0.429319  0.651042  \n",
       "14    0.049156  0.295985  0.651042  \n",
       "15    0.005177 -0.020681  0.651042  \n",
       "16    0.033785 -0.037348  0.651042  \n",
       "17   -0.093030 -0.037348  0.651042  \n",
       "18   -0.123346 -0.004015 -0.348958  \n",
       "19    0.024391 -0.020681  0.651042  \n",
       "20    0.099113 -0.104015 -0.348958  \n",
       "21   -0.035814  0.279319 -0.348958  \n",
       "22   -0.008914  0.129319  0.651042  \n",
       "23   -0.089187 -0.070681  0.651042  \n",
       "24   -0.093030  0.295985  0.651042  \n",
       "25   -0.113952  0.129319  0.651042  \n",
       "26   -0.091749  0.162652  0.651042  \n",
       "27    0.006458 -0.187348 -0.348958  \n",
       "28   -0.096873  0.395985 -0.348958  \n",
       "29   -0.057590  0.079319 -0.348958  \n",
       "..         ...       ...       ...  \n",
       "738  -0.008060 -0.204015 -0.348958  \n",
       "739  -0.076378  0.145985  0.651042  \n",
       "740   0.133699  0.245985  0.651042  \n",
       "741  -0.030690 -0.120681 -0.348958  \n",
       "742  -0.107975 -0.187348 -0.348958  \n",
       "743   0.111923  0.195985  0.651042  \n",
       "744   0.299797  0.095985 -0.348958  \n",
       "745   0.006885  0.212652 -0.348958  \n",
       "746  -0.048624 -0.104015  0.651042  \n",
       "747   0.266492 -0.020681 -0.348958  \n",
       "748  -0.027274  0.045985  0.651042  \n",
       "749  -0.125481  0.279319  0.651042  \n",
       "750   0.303213 -0.187348  0.651042  \n",
       "751  -0.090041 -0.087348 -0.348958  \n",
       "752  -0.106267 -0.137348 -0.348958  \n",
       "753  -0.106694 -0.120681  0.651042  \n",
       "754  -0.012330  0.195985  0.651042  \n",
       "755   0.249839  0.062652  0.651042  \n",
       "756  -0.034533  0.095985 -0.348958  \n",
       "757  -0.091322  0.312652  0.651042  \n",
       "758  -0.117368 -0.120681 -0.348958  \n",
       "759  -0.082782  0.545985  0.651042  \n",
       "760   0.125587 -0.187348 -0.348958  \n",
       "761  -0.029409  0.162652  0.651042  \n",
       "762  -0.140852 -0.004015 -0.348958  \n",
       "763  -0.128470  0.495985 -0.348958  \n",
       "764  -0.056309 -0.104015 -0.348958  \n",
       "765  -0.096873 -0.054015 -0.348958  \n",
       "766  -0.052466  0.229319  0.651042  \n",
       "767  -0.066984 -0.170681 -0.348958  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are 9 features - they are not normalised\n",
    "\n",
    "Pima_norm = (Pima - Pima.mean())/(Pima.max() - Pima.min())\n",
    "Pima_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_neighbors=10, p=2, weights='uniform')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KNeighborsClassifier(10)\n",
    "\n",
    "Pima \n",
    "to_predict = \"class\"\n",
    "features=['timespregnant', 'glucoseconc', 'dbp', 'trithickness', 'twohourins', 'bmi', 'pedigreef', 'age']\n",
    "X = Pima[features]\n",
    "y = Pima[to_predict]\n",
    "folds=5\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20, random_state=0)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79220779220779225"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.55      0.62        47\n",
      "          1       0.82      0.90      0.86       107\n",
      "\n",
      "avg / total       0.78      0.79      0.78       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print metrics.classification_report([Pima['class'][label] for label in y_test], \n",
    "                                    [Pima['class'][label] for label in model.predict(X_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.75875486,  0.71875   ,  0.73333333])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model, data, label, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.47      0.55        47\n",
      "          1       0.79      0.90      0.84       107\n",
      "\n",
      "avg / total       0.75      0.77      0.75       154\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Singleton array 0 cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-4753b294259f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m print metrics.classification_report([Pima['class'][label] for label in y_test], \n\u001b[0;32m     16\u001b[0m                                     [Pima['class'][label] for label in model.predict(X_test)])\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Lorna\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m   1348\u001b[0m         \u001b[0mArray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mscores\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mrun\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcross\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \"\"\"\n\u001b[1;32m-> 1350\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Lorna\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Lorna\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \"\"\"\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         raise ValueError(\"Found arrays with inconsistent numbers of samples: \"\n",
      "\u001b[1;32mC:\\Users\\Lorna\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[1;32m--> 120\u001b[1;33m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Singleton array 0 cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(50)\n",
    "\n",
    "Pima \n",
    "to_predict = \"class\"\n",
    "features=['timespregnant', 'glucoseconc', 'dbp', 'trithickness', 'twohourins', 'bmi', 'pedigreef', 'age']\n",
    "X = Pima[features]\n",
    "y = Pima[to_predict]\n",
    "folds=5\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20, random_state=0)\n",
    "model.fit(X_train,y_train)\n",
    "model.predict(X_test)\n",
    "model.score(X_test, y_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "print metrics.classification_report([Pima['class'][label] for label in y_test], \n",
    "                                    [Pima['class'][label] for label in model.predict(X_test)])\n",
    "cross_val_score(model, data, label, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-73-bb526caee148>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-73-bb526caee148>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    for n in range (1,50)\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for n in range (1,50)\n",
    "\n",
    "    model = KNeighborsClassifier(n)\n",
    "\n",
    "    Pima \n",
    "    to_predict = \"class\"\n",
    "    features=['timespregnant', 'glucoseconc', 'dbp', 'trithickness', 'twohourins', 'bmi', 'pedigreef', 'age']\n",
    "    X = Pima[features]\n",
    "    y = Pima[to_predict]\n",
    "    folds=5\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20, random_state=0)\n",
    "    model.fit(X_train,y_train)\n",
    "    model.predict(X_test)\n",
    "    model.score(X_test, y_test)\n",
    "    \n",
    "    print metrics.classification_report([Pima['class'][label] for label in y_test], \n",
    "                                    [Pima['class'][label] for label in model.predict(X_test)])\n",
    "    cross_val_score(model, data, label, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
